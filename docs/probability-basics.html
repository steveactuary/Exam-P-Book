<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Probability Basics | An Exam P Study Guide</title>
  <meta name="description" content="This is a study guide for exam P." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Probability Basics | An Exam P Study Guide" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a study guide for exam P." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Probability Basics | An Exam P Study Guide" />
  
  <meta name="twitter:description" content="This is a study guide for exam P." />
  

<meta name="author" content="Actuary Helper" />


<meta name="date" content="2019-12-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="counting.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<script src="libs/elevate-section-attrs-2.0/elevate-section-attrs.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint-0.0.1/kePrint.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> An Introduction to Set Theory</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#defining-sets"><i class="fa fa-check"></i><b>1.1</b> Defining Sets</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#set-equality-and-subsets"><i class="fa fa-check"></i><b>1.2</b> Set Equality and Subsets</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#set-operations-and-venn-diagrams"><i class="fa fa-check"></i><b>1.3</b> Set Operations and Venn Diagrams</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#venn-diagram"><i class="fa fa-check"></i><b>1.3.1</b> Venn Diagram</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#union"><i class="fa fa-check"></i><b>1.3.2</b> Union</a></li>
<li class="chapter" data-level="1.3.3" data-path="index.html"><a href="index.html#intersection"><i class="fa fa-check"></i><b>1.3.3</b> Intersection</a></li>
<li class="chapter" data-level="1.3.4" data-path="index.html"><a href="index.html#complement"><i class="fa fa-check"></i><b>1.3.4</b> Complement</a></li>
<li class="chapter" data-level="1.3.5" data-path="index.html"><a href="index.html#set-difference"><i class="fa fa-check"></i><b>1.3.5</b> Set Difference</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#special-sets-and-identities"><i class="fa fa-check"></i><b>1.4</b> Special Sets and Identities</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#sample-space-and-empty-set"><i class="fa fa-check"></i><b>1.4.1</b> Sample Space and Empty Set</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#de-morgans-laws"><i class="fa fa-check"></i><b>1.4.2</b> De Morgan’s Laws</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#or-more-sets"><i class="fa fa-check"></i><b>1.4.3</b> 3 or More Sets</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="counting.html"><a href="counting.html"><i class="fa fa-check"></i><b>2</b> Counting</a>
<ul>
<li class="chapter" data-level="2.1" data-path="counting.html"><a href="counting.html#size-of-a-set"><i class="fa fa-check"></i><b>2.1</b> Size of a set</a></li>
<li class="chapter" data-level="2.2" data-path="counting.html"><a href="counting.html#principle-of-inclusion-exclusion"><i class="fa fa-check"></i><b>2.2</b> Principle of Inclusion-Exclusion</a></li>
<li class="chapter" data-level="2.3" data-path="counting.html"><a href="counting.html#multiplication-principle"><i class="fa fa-check"></i><b>2.3</b> Multiplication Principle</a></li>
<li class="chapter" data-level="2.4" data-path="counting.html"><a href="counting.html#permutations"><i class="fa fa-check"></i><b>2.4</b> Permutations</a></li>
<li class="chapter" data-level="2.5" data-path="counting.html"><a href="counting.html#combinations"><i class="fa fa-check"></i><b>2.5</b> Combinations</a></li>
<li class="chapter" data-level="2.6" data-path="counting.html"><a href="counting.html#variations"><i class="fa fa-check"></i><b>2.6</b> Variations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability-basics.html"><a href="probability-basics.html"><i class="fa fa-check"></i><b>3</b> Probability Basics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability-basics.html"><a href="probability-basics.html#equiprob"><i class="fa fa-check"></i><b>3.1</b> Equally Likely Events</a></li>
<li class="chapter" data-level="3.2" data-path="probability-basics.html"><a href="probability-basics.html#terminology"><i class="fa fa-check"></i><b>3.2</b> Terminology</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="probability-basics.html"><a href="probability-basics.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>3.2.1</b> Sample Spaces and Events</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability-basics.html"><a href="probability-basics.html#probability-functions"><i class="fa fa-check"></i><b>3.3</b> Probability Functions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="probability-basics.html"><a href="probability-basics.html#axiomsprob"><i class="fa fa-check"></i><b>3.3.1</b> Probability Axioms</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="probability-basics.html"><a href="probability-basics.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>3.4</b> Conditional Probability and Independence</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probability-basics.html"><a href="probability-basics.html#condprob"><i class="fa fa-check"></i><b>3.4.1</b> Conditional Probability Formulas</a></li>
<li class="chapter" data-level="3.4.2" data-path="probability-basics.html"><a href="probability-basics.html#independence"><i class="fa fa-check"></i><b>3.4.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probability-basics.html"><a href="probability-basics.html#bayes-theorem"><i class="fa fa-check"></i><b>3.5</b> Bayes Theorem</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="probability-basics.html"><a href="probability-basics.html#bayes-theorem-intuition"><i class="fa fa-check"></i><b>3.5.1</b> Bayes Theorem Intuition</a></li>
<li class="chapter" data-level="3.5.2" data-path="probability-basics.html"><a href="probability-basics.html#law-of-total-probability"><i class="fa fa-check"></i><b>3.5.2</b> Law of Total Probability</a></li>
<li class="chapter" data-level="3.5.3" data-path="probability-basics.html"><a href="probability-basics.html#bayes-theorem-formula"><i class="fa fa-check"></i><b>3.5.3</b> Bayes Theorem Formula</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Exam P Study Guide</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability-basics" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Probability Basics</h1>
<div id="equiprob" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> Equally Likely Events</h2>
<p>If we flip a coin it is said that heads and tails have the same probability because the percentage of both heads and tails tend toward <span class="math inline">\(50\%\)</span> as the number of coin flips increases. Think of a <strong>probability</strong> as the percent of time an outcome occurs when many trials are performed. Here are the results of a simulation.</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Number of Trials
</th>
<th style="text-align:left;">
Percent Heads
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
60%
</td>
</tr>
<tr>
<td style="text-align:left;">
1,000
</td>
<td style="text-align:left;">
48.1%
</td>
</tr>
<tr>
<td style="text-align:left;">
100,000
</td>
<td style="text-align:left;">
50.005%
</td>
</tr>
</tbody>
</table>
<p>When we make a “random selection” it means that every possible selection has equal probability. For example, a randomly selected card from a deck of <span class="math inline">\(52\)</span> cards has probability <span class="math inline">\(\frac{1}{52}\)</span> of being a 2 of clubs.</p>
<p>When every possible outcome has equal probability, the formula for the probability of some subset of the outcomes is:</p>
<p><span class="math display">\[\frac{\text{Number of Selected Outcomes}}{\text{Number of Total Possible Outcomes}}\]</span></p>
<p>What is the probability of drawing 4 aces when we randomly select 5 cards from a deck? The number of ways to draw 4 aces is <span class="math inline">\({4 \choose 4} = 1\)</span> because there are 4 aces and we must select all of them. There are 48 cards to select that are not aces which leads to <span class="math inline">\({48 \choose 1} = 48\)</span> outcomes.</p>
<p>The number of ways to draw 4 aces is:
<span class="math display">\[{4 \choose 4}{48 \choose 1} = 48\]</span></p>
<p>The number of ways to draw 5 cards is:
<span class="math display">\[{52 \choose 5}\]</span></p>
<p>The answer is then:
<span class="math display">\[\frac{{4 \choose 4}{48 \choose 1}}{{52 \choose 5}} = \frac{48}{2598960} = \frac{1}{54145}\]</span></p>
</div>
<div id="terminology" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> Terminology</h2>
<div id="sample-spaces-and-events" class="section level3" number="3.2.1">
<h3 number="3.2.1"><span class="header-section-number">3.2.1</span> Sample Spaces and Events</h3>
<p>In probability we talk about experiments, sample spaces, and events.</p>
<p>When we flip a coin or roll a die that is an <strong>experiment</strong>. Experiments have a set of possible outcomes that happen with some probability.</p>
<p>The set of all possible outcomes of an experiment is the <strong>sample space</strong>. When we flip a coin once the sample space is <span class="math inline">\(S=\{H,T\}\)</span>. When we flip a coin twice the sample space is <span class="math inline">\(S=\{HH,HT,TH,TT\}\)</span>.</p>
<p><strong>Events</strong> represent a set of possible outcomes from an experiment. When we flip two coins there is an event for flipping two heads, <span class="math inline">\(E_\text{both heads}=\{HH\}\)</span>. There is also an event for not flipping two heads <span class="math inline">\(E_\text{not both heads}=\{HT,TH,TT\}\)</span>. An event is a subset of the sample space. It may represent a single outcome of our experiment, or it may represent several of the possible outcomes:
<span class="math display">\[E \subseteq S\]</span></p>
<p>We can rewrite our formula for probabilities when all outcomes of an experiment are equally likely using <span class="math inline">\(n(E)\)</span> for the number of selected outcomes.
<span class="math display">\[\frac{\text{Number of Selected Outcomes}}{\text{Number of Total Possible Outcomes}} = \frac{n(E)}{n(S)}\]</span></p>
<hr />
<p><strong>Example: Rolling Dice</strong></p>
<p>We roll two dice and want to calculate the probability that the dice sum to 4. Define the experiment, sample space, event, and calculate the probability of the event.</p>
<p>The experiment is rolling two dice.</p>
<p>The sample space has 36 elements, we can define it in set-builder notation:
<span class="math display">\[\{(a,b)|a,b \in \{1,2,3,4,5,6\}\}\]</span>
The event contains the elements of the sample space summing to 4.
<span class="math display">\[E = \{(1,3),(3,1),(2,2)\}\]</span>
The probability is
<span class="math display">\[\frac{\text{Number of Selected Outcomes}}{\text{Number of Total Possible Outcomes}} = \frac{n(E)}{n(S)} = \frac{3}{36}=\frac{1}{12}\]</span></p>
<hr />
</div>
</div>
<div id="probability-functions" class="section level2" number="3.3">
<h2 number="3.3"><span class="header-section-number">3.3</span> Probability Functions</h2>
<p>There is a function called a probability function, denoted <span class="math inline">\(P\)</span>, that calculates the probability of an event. When we flip a coin twice the probability of getting a head and a tail is:
<span class="math display">\[P(\{HT, TH\})=.5\]</span>
For experiments where all outcomes are equally likely:
<span class="math display">\[P(E) = \frac{n(E)}{n(S)}\]</span>
A probability is between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> because an event can’t happen less than <span class="math inline">\(0\%\)</span> of the time or more than <span class="math inline">\(100\%\)</span> of the time. More formally, <span class="math inline">\(P\)</span> is a function that takes an event as input and gives a number between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> as output. In notation:
<span class="math display">\[P:E \mapsto [0,1]\]</span></p>
<p>If we are being more mathematically rigorous, this rule about probabilities being between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> is derived from some more basic assumptions and not intuition about the percentage of times something occurs. Let’s talk about these basic assumptions.</p>
<div id="axiomsprob" class="section level3" number="3.3.1">
<h3 number="3.3.1"><span class="header-section-number">3.3.1</span> Probability Axioms</h3>
<p>There are three fundamental assumptions (called axioms) about probability functions from which our other laws are derived.</p>
<p><strong>First Axiom</strong> - For an event <span class="math inline">\(E\)</span>, and probability function <span class="math inline">\(P\)</span>:
<span class="math display">\[P(E) \geq 0\]</span>
<strong>Second Axiom</strong> - For a sample space <span class="math inline">\(S\)</span>:
<span class="math display">\[P(S)=1\]</span>
<strong>Third Axiom</strong> - If <span class="math inline">\(E1, E2, ...En\)</span> are <strong>mutually exclusive</strong> events:
<span class="math display">\[P(\bigcup\limits_{i=1}^{\infty} E_{i})=P(E_1 \cup E_2 \cup...\cup En \cup...) = P(E1)+P(E2)+...+P(En)+...\]</span>
For <strong>two mutually exclusive</strong> events events the third axiom is:
<span class="math display">\[P(E_1 \cup E_2) = P(E_1)+P(E_2)\]</span></p>
<p>There are several formulas that are useful for this exam that can be derived from these axioms. We can derive the formula for the probability of the complement of an event:
<span class="math display">\[P(A)+P(A^C) = P(A \cup A^C) = \ P(S) = 1 \ using \ Axioms \ 2 \ and \ 3\]</span>
Since <span class="math inline">\(P(A^C)+P(A) = 1 \implies P(A^C) = 1-P(A)\)</span>.</p>
<p>Here are some useful formulas that can be derived from these axioms.
<span class="math display">\[Complements: \ P(A^C) = 1 - P(A) \\
Upper \ Bound:P(A) \leq 1 \\
General \ Probability \ of \ 2 \ Unions: P(A \cup B) = P(A) + P(B) - P(A \cap B) \\
3 \ Unions: P(A \cup B \cup C) =  \\ P(A) + P(B) + P(C) - P(A \cap B)-P(B \cap C)-P(C \cap A) + P(A \cap B \cap C)\]</span></p>
<p>Notice that these formulas are the same as our formulas for the size of the set if we swap out <span class="math inline">\(P\)</span> for <span class="math inline">\(n\)</span> and <span class="math inline">\(1\)</span> for <span class="math inline">\(n(S)\)</span>.</p>
<hr />
<p><strong>Example: Coin Flipping and Axioms</strong></p>
<p>If we flip a coin, heads and tails are mutually exclusive events.
<span class="math display">\[P(\{H\} \cup \{T\}) = P(\{H\})+P(\{T\}) = .5 + .5 = 1\]</span>
We know that <span class="math inline">\(P(\{H\}), P(\{T\})=.5\)</span> from our formula for equally likely events at the beginning of the chapter. Note that <span class="math inline">\(S = \{H\} \cup \{T\}\)</span> so this example also illustrates that <span class="math inline">\(P(S)=1\)</span>.</p>
<hr />
</div>
</div>
<div id="conditional-probability-and-independence" class="section level2" number="3.4">
<h2 number="3.4"><span class="header-section-number">3.4</span> Conditional Probability and Independence</h2>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Fluffy
</th>
<th style="text-align:left;">
Not Fluffy
</th>
<th style="text-align:left;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;border-right:1px solid;">
Cats
</td>
<td style="text-align:left;">
21
</td>
<td style="text-align:left;">
18
</td>
<td style="text-align:left;font-weight: bold;">
39
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;border-right:1px solid;">
Dogs
</td>
<td style="text-align:left;">
35
</td>
<td style="text-align:left;">
26
</td>
<td style="text-align:left;font-weight: bold;">
61
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;border-right:1px solid;font-weight: bold;">
Total
</td>
<td style="text-align:left;font-weight: bold;">
56
</td>
<td style="text-align:left;font-weight: bold;">
44
</td>
<td style="text-align:left;font-weight: bold;font-weight: bold;">
100
</td>
</tr>
</tbody>
</table>
<p>We make estimates about the overall population of pets using the results of a survey about pets. To do this we pretend that the pets in the survey represent the entire population of pets.</p>
<p>We can calculate the probability of a pet being fluffy using our formula for <a href="probability-basics.html#equiprob">equally likely events</a>:
<span class="math display">\[\frac{\text{Number of Fluffy Pets}}{\text{Total Number of Pets}} = \frac{n(\text{Fluffy})}{n(\text{Pets})} = \frac{56}{100}\]</span></p>
<p>We can calculate the probability of a pet being a fluffy cat as:
<span class="math display">\[\frac{\text{Number of Fluffy Cats}}{\text{Total Number of Pets}} = \frac{n(\text{Fluffy} \cap \text{Cat})}{n(\text{Pets})} = \frac{21}{100}\]</span></p>
<p>We can also calculate the probability of a pet being fluffy, given that the pet is a cat:
<span class="math display">\[\frac{\text{Number of Fluffy Cats}}{\text{Total Number of Cats}} = \frac{n(\text{Fluffy} \cap \text{Cat})}{n(\text{Cats})}=\frac{21}{39}\]</span>
Calculating the probability of a pet being fluffy given that the pet is a cat is an example of conditional probability because in the denominator we do not include all of the possible pets, but only the cats. There is a special notation for conditional probabilities:
<span class="math display">\[\text{Probability Pet is Fluffy given that Pet is a Cat} = P(\text{Pet is Fluffy}|\text{Pet is a Cat})\]</span>
The general formula for conditional probabilities uses probabilities instead of set sizes. If all outcomes are equally likely either the probability or set size formula will give the same result:
<span class="math display">\[\frac{P(\text{Fluffy} \cap \text{Cat})}{P(\text{Cat})} =  
\frac{n(\text{Fluffy and Cat})/n(\text{Pets})}{n(\text{Cat})/n(\text{Pets})} = \frac{n(\text{Fluffy}\cap\text{Cat})}{n(\text{Cat})}\]</span></p>
<hr />
<div id="condprob" class="section level3" number="3.4.1">
<h3 number="3.4.1"><span class="header-section-number">3.4.1</span> Conditional Probability Formulas</h3>
<p>The probability of event <span class="math inline">\(A\)</span> given that event <span class="math inline">\(B\)</span> has occurred is denoted <span class="math inline">\(P(A|B)\)</span> and pronounced “the probability of A given B”.
The general formula for this is <span class="math display">\[P(A|B)=\frac{P(A \cap B)}{P(B)}\]</span></p>
<p>For experiments where all outcomes have equal probabilities <span class="math inline">\(P(A|B)\)</span> can be calculated with set sizes. The derivation for forumla this was done in our example with fluffy cats. <span class="math display">\[P(A|B)=\frac{n(A \cap B)}{n(B)}\]</span></p>
<p>We can calculate the probability of the intersection using the probability of the given event with the conditional probability. This formula is easiest to conceptualize if you imagine an event B happening with probability <span class="math inline">\(P(B)\)</span> and then an event <span class="math inline">\(A\)</span> happening with probability <span class="math inline">\(P(A|B)\)</span>. <span class="math display">\[P(A|B) \times P(B) = P(A \cap B)\]</span></p>
<hr />
</div>
<div id="independence" class="section level3" number="3.4.2">
<h3 number="3.4.2"><span class="header-section-number">3.4.2</span> Independence</h3>
<p>Events are independent if they do not influence each other. The first flip of a coin will not impact the second flip so these events are independent.</p>
<p>Let the event that the first card pulled without replacement from a deck is a jack be <span class="math inline">\(J_1\)</span> and the event that the second card pulled is a jack is <span class="math inline">\(J_2\)</span>. If I pull a jack on my first try there will be less jacks in the deck for the second draw. The event <span class="math inline">\(J_1\)</span> has an effect on <span class="math inline">\(J_2\)</span> and these events are not independent.</p>
<p><strong>Definition of Independence</strong>: Events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be independent if <span class="math inline">\(P(A|B)=P(A)\)</span>.</p>
<p>This definition is equivalent to <span class="math inline">\(P(A \cap B) = P(A) \times P(B)\)</span> after substitution with the <a href="probability-basics.html#condprob">conditional probability formulas</a>. This identity has it’s own name:</p>
<p><strong>Multiplication Rule for Independent Events</strong>: If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent events then <span class="math inline">\(P(A \cap B) = P(A) \times P(B)\)</span>.</p>
<p>Let <span class="math inline">\(H_n\)</span> be the event that the nth flip of a coin is heads so that <span class="math inline">\(H_2\)</span> means the second coin flip is heads. The multiplication rule for independent events works for more than two events if all events are mutually independent so that <span class="math inline">\(P(H_1 \cap H_2 \cap H_3 \cap H_4)=P(H_1)\times P(H_2)\times P(H_3)\times P(H_4) = (\frac{1}{2})^4\)</span>.</p>
</div>
</div>
<div id="bayes-theorem" class="section level2" number="3.5">
<h2 number="3.5"><span class="header-section-number">3.5</span> Bayes Theorem</h2>
<div id="bayes-theorem-intuition" class="section level3" number="3.5.1">
<h3 number="3.5.1"><span class="header-section-number">3.5.1</span> Bayes Theorem Intuition</h3>
<p>Suppose 1% of the population uses drugs. 98% of drug users test positive on a drug test and 2% of non-users test positive. What is the probability that a person testing positive for a drug test has used drugs?</p>
<p><img src="Pictures/03-Probability/BayesTreeSmall.PNG" /></p>
<p>Using the above tree diagram and the definition of conditional probability we calculate: <span class="math display">\[P(User|Positive) = \frac{P(User \cap Positive)}{P(Positive)}= \\ 
\frac{P(User \cap Positive)}{P(Positive \cap Not \ User) + (Positive \cap User)} =\\  \frac{P(Positive|User) \times P(User)}{P(Positive|User) \times P(User)+P(Positive|Not \ User) \times P(Not \ User)} = \\
\frac{.0099}{.0099+.0099}=\frac{1}{2}\]</span></p>
<p>Let’s explain these steps in more detail.</p>
</div>
<div id="law-of-total-probability" class="section level3" number="3.5.2">
<h3 number="3.5.2"><span class="header-section-number">3.5.2</span> Law of Total Probability</h3>
<p>In our calculation when we go from the first to the second line we use the identity <span class="math inline">\(P(Positive)=P(Positive \cap User)+P(Positive \cap Not \ User)\)</span>, but how do we know this is true?
<span class="math inline">\(Positive \cap User\)</span> only contains drug users and <span class="math inline">\(Positive \cap Not \ User\)</span> only contains non-users. These events are mutually exclusive so <span class="math inline">\(P(Positive \cap User)+P(Positive \cap Not \ User) = P((Positive \cap User) \cup (Positive \cap Not \ User))\)</span> using our <a href="probability-basics.html#axiomsprob">third probability axiom</a>. Using the distributive property for intersections with the identities
<span class="math display">\[A^C \cup A = Sample \ Space, \quad A \cap (Sample \ Space) = A\]</span>
we can see that:
<span class="math display">\[(Positive \cap User) \cup (Positive \cap Not \ User) = Positive \cap (User \cup Not \ User) = \\ Positive \cap (Sample \ Space) = Positive\]</span>
This is how we know that <span class="math inline">\(P(Positive)=P(Positive \cap User)+P(Positive \cap Not \ User)\)</span>.</p>
<p>There is a more general formulation of this known as the <strong>law of total probability</strong>:</p>
<hr />
<p>Events <span class="math inline">\(A_1,A_2,...,A_n\)</span> are said to be a <strong>partition</strong> of the sample space <span class="math inline">\(S\)</span> if <span class="math inline">\(A_1 \cup A_2 \cup... \cup A_n=S\)</span> and if for all <span class="math inline">\(i,j: \ A_i \cap A_j = \emptyset\)</span>. This just means that the sets <span class="math inline">\(A_1,A_2,...,A_n\)</span> cover the whole set and there is no overlap between the sets.</p>
<p>If sets <span class="math inline">\(A_1,A_2,...,A_n\)</span> partition <span class="math inline">\(S\)</span> then for any event <span class="math inline">\(E\)</span> we have <strong>the law of total probability</strong>:
<span class="math display">\[P(E) = P(E \cap (A_1 \cup A_2 \cup ... \cup A_n)) = \\ P(E \cap A_1) + P(E \cap A_2) + ... + P(E \cap A_n) = \\ P(E|A_1) \times P(A_1) +...+ P(E|A_n) \times P(A_n)\]</span></p>
<p>Here is a visual:</p>
<p><img src="Pictures/03-Probability/totalprob.PNG" /></p>
<p>The proof of the law of total probability is outlined in our discussion of drug users.</p>
<hr />
</div>
<div id="bayes-theorem-formula" class="section level3" number="3.5.3">
<h3 number="3.5.3"><span class="header-section-number">3.5.3</span> Bayes Theorem Formula</h3>
<div id="derivation-using-law-of-total-probability" class="section level4" number="3.5.3.1">
<h4 number="3.5.3.1"><span class="header-section-number">3.5.3.1</span> Derivation Using Law of Total Probability</h4>
<p>In our previous example every person is either a drug user or not so this partitions the sample space into two regions, <span class="math inline">\(User\)</span> and <span class="math inline">\(Not \ User\)</span>. We can use the definition of conditional probability to say:
<span class="math display">\[P(User|Positive)=\frac{P(User \cap Positive)}{P(Positive)}\]</span>
We use the law of total probability in the denominator to expand it and convert all expressions of the form <span class="math inline">\(P(A \cap B)\)</span> to expressions of the form <span class="math inline">\(P(B | A) \times P(A)\)</span>. The result is:
<span class="math display">\[\frac{P(Positive|User) \times P(User)}{P(Positive|User) \times P(User)+P(Positive|Not \ User) \times P(Not \ User)}\]</span></p>
</div>
<div id="bayes-theorem-statement" class="section level4" number="3.5.3.2">
<h4 number="3.5.3.2"><span class="header-section-number">3.5.3.2</span> Bayes Theorem Statement</h4>
<p>For a partition <span class="math inline">\(A_1,A_2,...,A_n\)</span> and event <span class="math inline">\(E\)</span>:
<span class="math display">\[P(E|A_k) = \frac{P(E|A_k) \times P(A_k)}{P(E|A_1) \times P(A_1) +...+ P(E|A_n) \times P(A_n)}\]</span></p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="counting.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03-probability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
